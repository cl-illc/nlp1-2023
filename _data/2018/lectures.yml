-
  layout: lecture
  selected: y
  date: 2022-10-31
  img: introduction-icon_1-267x300
  uid: intro
  title: "Introduction"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "Introduction to the course"
  background:
  discussion:
  slides: resources/slides/NLP1-lecture1.pdf
  video: 
  further: 
    - "Chapter 4: [Naive Bayes classification and sentiment](https://web.stanford.edu/~jurafsky/slp3/4.pdf) in Jurafsky and Martin (3rd edition)."
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2022-11-02
  img: PoS
  uid: lec2
  title: "Language modelling"
  instructor: "Wilker Aziz"
  note: 
  abstract: >
    "In this lecture, we will discuss language models, i.e. modelling word sequences, using statistical techniques."
  background:
  discussion:
  slides: 
  video: 
  further: 
    - "Chapter 3: [Language modelling with n-grams](https://web.stanford.edu/~jurafsky/slp3/3.pdf) in Jurafsky and Martin (3rd edition)."
  code: 
  data:  
-
  layout: lecture
  selected: y
  date: 2022-11-07
  img: Parsing
  uid: lec3
  title: "Morphology and part-of-speech tagging"
  instructor: "Wilker Aziz"
  note: 
  abstract: >
    "In this lecture, we will discuss morphological processing and part-of-speech tagging."
  background:
  discussion:
  slides: 
  video:
  further: 
    - "Lecture notes on moprphology are available [here](https://cl-illc.github.io/nlp1/resources/slides/Morphology-notes.pdf)"
    - "Chapter 8: [Part-of-speech tagging](https://web.stanford.edu/~jurafsky/slp3/8.pdf) in Jurafsky and Martin (3rd edition)."
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2022-11-09
  img: vectors
  uid: lec4
  title: "Modelling structure: Syntax and semantics"
  instructor: "Wilker Aziz"
  note: 
  abstract: >
    "In this lecture, we will introduce syntax and discuss algorithms for syntactic and semantic parsing"
  background:
  discussion:
  slides: 
  video: 
  further: 
    - "Chapter 12: [Constituency grammars](https://web.stanford.edu/~jurafsky/slp3/12.pdf) in Jurafsky and Martin (3rd edition)."
    - "Chapter 13: [Constituency parsing](https://web.stanford.edu/~jurafsky/slp3/13.pdf) in Jurafsky and Martin (3rd edition)."
  data:  
-
  layout: lecture
  selected: y
  date: 2022-11-14
  img: skip-gram
  uid: lec5
  title: "Lexical semantics and word embeddings"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this lecture, we will introduce statistical models of word meaning, discuss generalisation from words to semantic classes and learning dense vector representations - word embeddings."
  background:
  discussion:
  slides: 
  further: 
    - "Chapter 19: [Word Senses and WordNet](https://web.stanford.edu/~jurafsky/slp3/19.pdf) in Jurafsky and Martin (3rd edition)."
    - "Chapter 6: [Vector semantics and embeddings](https://web.stanford.edu/~jurafsky/slp3/6.pdf) in Jurafsky and Martin (3rd edition)."
    - "A gentle introduction to neural networks can be found [here](http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/)"
    - "The following paper provides a nice explanation of skip-gram with negative sampling: Yoav Goldberg and Omer Levy. [word2vec Explained: Deriving Mikolov et al.â€™s Negative-Sampling Word-Embedding Method](https://arxiv.org/pdf/1402.3722.pdf)"
  video: 
  code: 
  data:    
-
  layout: lecture
  selected: y
  date: 2022-11-16
  img: srn
  uid: lec6
  title: "Compositional semantics and sentence representations"
  instructor: "Rochelle Choenni"
  note: 
  abstract: >
    "In this lecture, we will discuss compositional semantics, i.e. modelling the meaning of phrases and sentences, and learning neural representations of sentences."
  background:
  discussion:
  slides: 
  further: 
    - "Chapter 7: [Neural networks and neural language models](https://web.stanford.edu/~jurafsky/slp3/7.pdf) in Jurafsky and Martin (3rd edition)."
    - "Chapter 9: [Sequence processing with recurrent neural networks](https://web.stanford.edu/~jurafsky/slp3/9.pdf) in Jurafsky and Martin (3rd edition)."
    - "A good and general reference for Neural Networks in NLP: Yoav Goldberg. [A Primer on Neural Network Models for Natural Language Processing](https://arxiv.org/abs/1510.00726)"
    - "A gentle introduction to LSTMs is available [here](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
    - "This is one of the papers that have introduced tree LSTM models: Kai Sheng Tai, Richard Socher, and Christopher D. Manning. [Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks](http://aclweb.org/anthology/P/P15/P15-1150.pdf)" 
  video: 
  code: 
  data:    
-
  layout: lecture
  selected: y
  date: 2022-11-21
  img: Discourse
  uid: lec7
  title: "Discourse processing"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this lecture, we will discuss discourse processing, i.e. modelling larger text fragments."
  background:
  discussion:
  slides: 
  further: 
    - "Chapter 22: [Coreference resolution](https://web.stanford.edu/~jurafsky/slp3/22.pdf) in Jurafsky and Martin (3rd edition)."
    - "Chapter 23: [Discourse coherence](https://web.stanford.edu/~jurafsky/slp3/23.pdf) in Jurafsky and Martin (3rd edition)." 
  video: 
  code: 
  data:  
-
  layout: lecture
  selected: y
  date: 2022-11-28
  img: srn
  uid: lec8
  title: "Large language models"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this session, we will discuss large language models, their pretraining strategies, their architectures and their applications."
  background:
  discussion:
  slides: 
  further:
  video: 
  code: 
  data:  
-
  layout: lecture
  selected: y
  date: 2022-11-30
  img: Twitter
  uid: lec9
  title: "Interpretability of NLP models"
  instructor: "Jaap Jumelet"
  note: 
  abstract: >
    "We will discuss techniques that allow us to better understand what kind of information neural language models encode and how they do it."
  background:
  discussion:
  slides: 
  further: 
  video: 
  code: 
  data:  
-
  layout: lecture
  selected: y
  date: 2022-12-05
  img: Summarization
  uid: lec10
  title: "Language generation and summarisation"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this lecture, we will talk about language generation and cover a particular language generation task, text summarisation, in more detail."
  background:
  discussion:
  slides: 
  further: 
    - "A survey of recent summarisation techniques is available [here](https://arxiv.org/pdf/1804.04589.pdf)"
    - "An introduction to sequence-to-sequence models: [Sequence to Sequence Learning with Neural Networks](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)"
  video: 
  code: 
  data:  
-
  layout: lecture
  selected: y
  date: 2022-12-07
  img: MT
  uid: lec11
  title: "Machine translation"
  instructor: "Christof Monz"
  note: 
  abstract: >
    "We will discuss the fundamentals of machine translation, including word-based / alignment models and phrase-based SMT"
  background:
  discussion:
  slides: 
  further: 
    - "[Neural Encoder-Decoder](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)"
    - "[The Annotated Encoder-Decoder blog post](https://bastings.github.io/annotated_encoder_decoder/)"
  video: 
  code: 
  data:  
-
  layout: lecture
  selected: y
  date: 2022-12-12
  img: dialogue
  uid: lec12
  title: "Dialogue modelling"
  instructor: "Alberto Testoni and Esam Ghaleb"
  note: 
  abstract: >
    "In this lecture, we will introduce an important NLP application -- dialogue modelling."
  background:
  discussion:
  slides: 
  further:
    - "Chapter 26: [Dialogue systems and chatbots](https://web.stanford.edu/~jurafsky/slp3/26.pdf) in Jurafsky and Martin (3rd edition)."
  video: 
  code: 
  data:    
-
  layout: lecture
  selected: y
  date: 2020-12-14
  img: Live-1
  uid: lec-final
  title: "Summary of the course and Q&A"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this lecture, we will give you a brief summary of the course and how different areas we have studied interface. We will also discuss what to expect at the exam."
  background:
  discussion:
  slides: 
  further:
  video: 
  code: 
  data:   

